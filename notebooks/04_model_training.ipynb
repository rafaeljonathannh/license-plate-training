{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training - Indonesian License Plate Detection\n",
    "\n",
    "**Purpose:** Train YOLOv8 model directly on clean Roboflow dataset with optimal baseline parameters.\n",
    "\n",
    "This notebook implements the optimized training approach from CLAUDE.md."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Libraries imported successfully\n",
      "Working directory: c:\\Users\\Rafael Jonathan\\Desktop\\license-plate-training\n",
      "PyTorch version: 2.7.1+cpu\n",
      "‚ö†Ô∏è  CUDA not available - will use CPU (slower)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import json\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "# Import YOLOv8\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(\"üì¶ Libraries imported successfully\")\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ CUDA available\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU Memory: {gpu_memory:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  CUDA not available - will use CPU (slower)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóÇÔ∏è  Dataset location: ..\\dataset\\plat-kendaraan\n",
      "üìÅ Models directory: ..\\models\n",
      "‚úÖ Dataset found with configuration: ..\\dataset\\plat-kendaraan\\data.yaml\n",
      "\n",
      "üìã Dataset Configuration:\n",
      "  names: ['License_Plate']\n",
      "  nc: 1\n",
      "  roboflow: {'license': 'MIT', 'project': 'vehicle-and-license-plate', 'url': 'https://universe.roboflow.com/plat-kendaraan/vehicle-and-license-plate/dataset/1', 'version': 1, 'workspace': 'plat-kendaraan'}\n",
      "  test: ../test/images\n",
      "  train: ../train/images\n",
      "  val: ../valid/images\n",
      "\n",
      "üîç Dataset Structure:\n",
      "  train:  5100 images,  5100 labels\n",
      "  valid:   432 images,   432 labels\n",
      "   test:    21 images,    21 labels\n"
     ]
    }
   ],
   "source": [
    "# Define paths (portable structure with updated root)\n",
    "BASE_DIR = Path(\"..\")\n",
    "DATASET_PATH = BASE_DIR / \"dataset\" / \"plat-kendaraan\"\n",
    "MODELS_DIR = BASE_DIR / \"models\"\n",
    "EXPERIMENTS_DIR = MODELS_DIR / \"experiments\"\n",
    "FINAL_MODELS_DIR = MODELS_DIR / \"final\"\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "\n",
    "# Create directories\n",
    "for directory in [EXPERIMENTS_DIR, FINAL_MODELS_DIR, RESULTS_DIR]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üóÇÔ∏è  Dataset location: {DATASET_PATH}\")\n",
    "print(f\"üìÅ Models directory: {MODELS_DIR}\")\n",
    "\n",
    "# Check if dataset exists\n",
    "if DATASET_PATH.exists():\n",
    "    data_yaml = DATASET_PATH / \"data.yaml\"\n",
    "    if data_yaml.exists():\n",
    "        print(f\"‚úÖ Dataset found with configuration: {data_yaml}\")\n",
    "        \n",
    "        # Load and display config\n",
    "        with open(data_yaml, 'r') as f:\n",
    "            dataset_config = yaml.safe_load(f)\n",
    "        \n",
    "        print(\"\\nüìã Dataset Configuration:\")\n",
    "        for key, value in dataset_config.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        \n",
    "        dataset_ready = True\n",
    "    else:\n",
    "        print(f\"‚ùå data.yaml not found at: {data_yaml}\")\n",
    "        dataset_ready = False\n",
    "else:\n",
    "    print(f\"‚ùå Dataset not found at: {DATASET_PATH}\")\n",
    "    print(\"Please run notebook 01 to download the dataset first.\")\n",
    "    dataset_ready = False\n",
    "\n",
    "# Verify dataset structure\n",
    "if dataset_ready:\n",
    "    print(\"\\nüîç Dataset Structure:\")\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        split_path = DATASET_PATH / split\n",
    "        if split_path.exists():\n",
    "            images = len(list((split_path / 'images').glob('*.jpg')))\n",
    "            labels = len(list((split_path / 'labels').glob('*.txt')))\n",
    "            print(f\"  {split:>5}: {images:>5} images, {labels:>5} labels\")\n",
    "        else:\n",
    "            print(f\"  {split:>5}: ‚ùå Not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Optimal Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  CPU mode: batch size 4, workers 2\n",
      "\n",
      "üéØ Training Configuration:\n",
      "==============================\n",
      "    epochs: 100\n",
      "     batch: 4\n",
      "     imgsz: 640\n",
      " optimizer: AdamW\n",
      "       lr0: 0.001\n",
      "  patience: 15\n",
      "    device: cpu\n",
      "\n",
      "üöÄ Experiment: yolov8n_baseline_20250806_212145\n",
      "üìä Results will be saved to: ..\\models\\experiments\\yolov8n_baseline_20250806_212145\n"
     ]
    }
   ],
   "source": [
    "# Create experiment name\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "experiment_name = f\"yolov8n_baseline_{timestamp}\"\n",
    "\n",
    "# Optimal baseline configuration (from CLAUDE.md)\n",
    "training_config = {\n",
    "    # Core parameters\n",
    "    \"data\": str(DATASET_PATH / \"data.yaml\"),\n",
    "    \"epochs\": 100,\n",
    "    \"patience\": 15,      # Early stopping\n",
    "    \"batch\": 16,         # Good balance for 8GB+ GPU  \n",
    "    \"imgsz\": 640,        # Standard YOLO size\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"lr0\": 0.001,        # Conservative learning rate\n",
    "    \"val\": True,\n",
    "    \"save\": True,\n",
    "    \"plots\": True,\n",
    "    \n",
    "    # Output configuration\n",
    "    \"project\": str(EXPERIMENTS_DIR),\n",
    "    \"name\": experiment_name,\n",
    "    \"exist_ok\": True,\n",
    "    \n",
    "    # Performance settings\n",
    "    \"device\": 0 if torch.cuda.is_available() else \"cpu\",\n",
    "    \"workers\": 4 if torch.cuda.is_available() else 2,\n",
    "    \"cache\": False,      # Save memory\n",
    "    \"verbose\": True\n",
    "}\n",
    "\n",
    "# Adjust batch size based on GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    if gpu_memory < 8:\n",
    "        training_config[\"batch\"] = 8\n",
    "        print(f\"‚ö†Ô∏è  Adjusted batch size to 8 for {gpu_memory:.1f} GB GPU\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Using batch size 16 with {gpu_memory:.1f} GB GPU\")\n",
    "else:\n",
    "    training_config[\"batch\"] = 4\n",
    "    training_config[\"workers\"] = 2\n",
    "    print(\"‚ö†Ô∏è  CPU mode: batch size 4, workers 2\")\n",
    "\n",
    "print(\"\\nüéØ Training Configuration:\")\n",
    "print(\"=\" * 30)\n",
    "key_params = [\"epochs\", \"batch\", \"imgsz\", \"optimizer\", \"lr0\", \"patience\", \"device\"]\n",
    "for key in key_params:\n",
    "    print(f\"{key:>10}: {training_config[key]}\")\n",
    "\n",
    "print(f\"\\nüöÄ Experiment: {experiment_name}\")\n",
    "print(f\"üìä Results will be saved to: {EXPERIMENTS_DIR / experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load YOLOv8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Loading YOLOv8n model...\n",
      "‚úÖ YOLOv8n model loaded successfully\n",
      "\n",
      "üìã Model Information:\n"
     ]
    }
   ],
   "source": [
    "if dataset_ready:\n",
    "    print(\"ü§ñ Loading YOLOv8n model...\")\n",
    "    \n",
    "    try:\n",
    "        # Load pre-trained YOLOv8 nano model\n",
    "        model = YOLO('yolov8n.pt')\n",
    "        print(\"‚úÖ YOLOv8n model loaded successfully\")\n",
    "        \n",
    "        # Display model info\n",
    "        print(\"\\nüìã Model Information:\")\n",
    "        model.info(verbose=False)\n",
    "        \n",
    "        model_ready = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load model: {e}\")\n",
    "        model_ready = False\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping model loading - dataset not ready\")\n",
    "    model_ready = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting YOLOv8 training...\n",
      "Target: mAP@0.5 > 0.85\n",
      "Training will stop early if no improvement for 15 epochs\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.174 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.173  Python-3.13.2 torch-2.7.1+cpu CPU (Intel Core(TM) Ultra 7 155H)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=..\\dataset\\plat-kendaraan\\data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n_baseline_20250806_212145, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=..\\models\\experiments, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=..\\models\\experiments\\yolov8n_baseline_20250806_212145, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.0 ms, read: 3.61.3 MB/s, size: 61.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Rafael Jonathan\\Desktop\\dataset\\plat-kendaraan\\train\\labels... 5100 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5100/5100 [00:23<00:00, 219.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\Rafael Jonathan\\Desktop\\dataset\\plat-kendaraan\\train\\labels.cache\n",
      "WARNING Box and segment counts should be equal, but got len(segments) = 1634, len(boxes) = 5364. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 5.20.8 MB/s, size: 72.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rafael Jonathan\\Desktop\\license-plate-training\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Rafael Jonathan\\Desktop\\dataset\\plat-kendaraan\\valid\\labels... 432 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 432/432 [00:03<00:00, 143.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Rafael Jonathan\\Desktop\\dataset\\plat-kendaraan\\valid\\labels.cache\n",
      "WARNING Box and segment counts should be equal, but got len(segments) = 143, len(boxes) = 463. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\Rafael Jonathan\\Desktop\\license-plate-training\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to ..\\models\\experiments\\yolov8n_baseline_20250806_212145\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m..\\models\\experiments\\yolov8n_baseline_20250806_212145\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100         0G      1.309       1.18      1.177          4        640:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 947/1275 [19:06<09:06,  1.67s/it]"
     ]
    }
   ],
   "source": [
    "if dataset_ready and model_ready:\n",
    "    print(\"üöÄ Starting YOLOv8 training...\")\n",
    "    print(f\"Target: mAP@0.5 > 0.85\")\n",
    "    print(f\"Training will stop early if no improvement for {training_config['patience']} epochs\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Start training\n",
    "        results = model.train(**training_config)\n",
    "        \n",
    "        print(\"\\nüéâ Training completed successfully!\")\n",
    "        print(f\"üìä Results saved to: {EXPERIMENTS_DIR / experiment_name}\")\n",
    "        \n",
    "        training_success = True\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚èπÔ∏è  Training interrupted by user\")\n",
    "        training_success = False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Training failed: {e}\")\n",
    "        print(\"\\nüîß Troubleshooting tips:\")\n",
    "        print(\"  ‚Ä¢ Reduce batch size if out of memory\")\n",
    "        print(\"  ‚Ä¢ Check dataset paths in data.yaml\")\n",
    "        print(\"  ‚Ä¢ Verify GPU/CUDA installation\")\n",
    "        training_success = False\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Cannot start training:\")\n",
    "    if not dataset_ready:\n",
    "        print(\"  ‚Ä¢ Dataset not ready - run cells above\")\n",
    "    if not model_ready:\n",
    "        print(\"  ‚Ä¢ Model not loaded - check previous cell\")\n",
    "    training_success = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'training_success' in locals() and training_success:\n",
    "    print(\"üìä Analyzing training results...\")\n",
    "    \n",
    "    # Find experiment directory\n",
    "    exp_dir = EXPERIMENTS_DIR / experiment_name\n",
    "    \n",
    "    if exp_dir.exists():\n",
    "        print(f\"‚úÖ Experiment directory: {exp_dir}\")\n",
    "        \n",
    "        # Check for results files\n",
    "        results_csv = exp_dir / \"results.csv\"\n",
    "        if results_csv.exists():\n",
    "            import pandas as pd\n",
    "            \n",
    "            # Load training metrics\n",
    "            df = pd.read_csv(results_csv)\n",
    "            print(f\"\\nüìà Training completed in {len(df)} epochs\")\n",
    "            \n",
    "            # Extract key metrics from final epoch\n",
    "            final_metrics = df.iloc[-1]\n",
    "            \n",
    "            print(\"\\nüéØ Final Performance:\")\n",
    "            print(\"=\" * 25)\n",
    "            \n",
    "            # Key metrics to display\n",
    "            metric_names = {\n",
    "                'metrics/mAP50(B)': 'mAP@0.5',\n",
    "                'metrics/mAP50-95(B)': 'mAP@0.5:0.95', \n",
    "                'metrics/precision(B)': 'Precision',\n",
    "                'metrics/recall(B)': 'Recall',\n",
    "                'train/box_loss': 'Box Loss',\n",
    "                'val/box_loss': 'Val Box Loss'\n",
    "            }\n",
    "            \n",
    "            for col, name in metric_names.items():\n",
    "                if col in df.columns:\n",
    "                    value = final_metrics[col]\n",
    "                    if 'loss' in col.lower():\n",
    "                        print(f\"{name:>12}: {value:.4f}\")\n",
    "                    else:\n",
    "                        print(f\"{name:>12}: {value:.3f}\")\n",
    "            \n",
    "            # Check if target mAP@0.5 > 0.85 was achieved\n",
    "            map50_col = 'metrics/mAP50(B)'\n",
    "            if map50_col in df.columns:\n",
    "                final_map50 = final_metrics[map50_col]\n",
    "                target_map50 = 0.85\n",
    "                \n",
    "                print(f\"\\nüéØ Performance vs Target:\")\n",
    "                print(f\"Final mAP@0.5: {final_map50:.3f}\")\n",
    "                print(f\"Target mAP@0.5: {target_map50:.3f}\")\n",
    "                \n",
    "                if final_map50 >= target_map50:\n",
    "                    print(\"‚úÖ TARGET ACHIEVED! Model ready for production.\")\n",
    "                else:\n",
    "                    gap = target_map50 - final_map50\n",
    "                    print(f\"‚ö†Ô∏è  Target not reached (gap: {gap:.3f})\")\n",
    "                    print(\"üí° Consider: upgrade to yolov8s, increase epochs, or tune hyperparameters\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  results.csv not found\")\n",
    "            \n",
    "        # List generated files\n",
    "        print(f\"\\nüìÅ Generated files in {exp_dir}:\")\n",
    "        for item in exp_dir.rglob('*'):\n",
    "            if item.is_file():\n",
    "                rel_path = item.relative_to(exp_dir)\n",
    "                print(f\"  üìÑ {rel_path}\")\n",
    "                \n",
    "    else:\n",
    "        print(f\"‚ùå Experiment directory not found: {exp_dir}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No training results to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Best Model for Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'training_success' in locals() and training_success:\n",
    "    print(\"üì¶ Exporting best model for production...\")\n",
    "    \n",
    "    exp_dir = EXPERIMENTS_DIR / experiment_name\n",
    "    weights_dir = exp_dir / \"weights\"\n",
    "    best_weights = weights_dir / \"best.pt\"\n",
    "    \n",
    "    if best_weights.exists():\n",
    "        # Copy best model to final models directory\n",
    "        final_model_name = f\"yolov8n_indonesian_plates_{timestamp}.pt\"\n",
    "        final_model_path = FINAL_MODELS_DIR / final_model_name\n",
    "        \n",
    "        shutil.copy2(best_weights, final_model_path)\n",
    "        print(f\"‚úÖ Model saved as: {final_model_path}\")\n",
    "        \n",
    "        # Create best_model.pt link (as specified in CLAUDE.md)\n",
    "        best_model_link = FINAL_MODELS_DIR / \"best_model.pt\"\n",
    "        if best_model_link.exists():\n",
    "            best_model_link.unlink()\n",
    "        \n",
    "        shutil.copy2(final_model_path, best_model_link)\n",
    "        print(f\"‚úÖ Created production link: {best_model_link}\")\n",
    "        \n",
    "        # Check model size (target < 50MB from CLAUDE.md)\n",
    "        model_size_mb = final_model_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"üìè Model size: {model_size_mb:.1f} MB\")\n",
    "        \n",
    "        if model_size_mb < 50:\n",
    "            print(\"‚úÖ Model size meets deployment requirement (< 50MB)\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Model exceeds 50MB target for deployment\")\n",
    "        \n",
    "        # Test model loading\n",
    "        print(\"\\nüß™ Testing model loading...\")\n",
    "        try:\n",
    "            test_model = YOLO(str(final_model_path))\n",
    "            print(\"‚úÖ Model loads successfully\")\n",
    "            \n",
    "            # Model info\n",
    "            print(f\"Model classes: {test_model.names}\")\n",
    "            print(f\"Model device: {test_model.device}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Model loading failed: {e}\")\n",
    "        \n",
    "        print(f\"\\nüöÄ Model ready for production integration!\")\n",
    "        print(f\"Next: Run notebook 05_evaluation_export.ipynb for detailed evaluation\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå Best weights not found at: {best_weights}\")\n",
    "        print(\"Check if training completed successfully\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No trained model to export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### ‚úÖ Training Configuration Used:\n",
    "- **Model**: YOLOv8n (optimized for speed/size balance)\n",
    "- **Epochs**: 100 with early stopping (patience=15)\n",
    "- **Batch Size**: 16 (GPU) / 8 (low memory) / 4 (CPU)\n",
    "- **Image Size**: 640√ó640 (standard YOLO)\n",
    "- **Optimizer**: AdamW with lr=0.001\n",
    "\n",
    "### üéØ Performance Targets (CLAUDE.md):\n",
    "- **Accuracy**: mAP@0.5 > 0.85 ‚úÖ/‚ö†Ô∏è\n",
    "- **Speed**: < 100ms per image (GPU inference)\n",
    "- **Model Size**: < 50MB for deployment\n",
    "- **Confidence**: >= 0.3 threshold\n",
    "\n",
    "### üí° If Target Not Met - Tuning Options:\n",
    "1. **Model Upgrade**: yolov8n ‚Üí yolov8s ‚Üí yolov8m\n",
    "2. **Batch Size**: 8/16/32 (GPU memory dependent)\n",
    "3. **Image Size**: 640 ‚Üí 832 ‚Üí 1024 (accuracy vs speed)\n",
    "4. **Learning Rate**: 0.0005 ‚Üí 0.002 (fine-tuning)\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "1. **Check training results above**\n",
    "2. **Run notebook 05_evaluation_export.ipynb for detailed evaluation**\n",
    "3. **Test model on sample images**\n",
    "4. **Integrate with production system**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
