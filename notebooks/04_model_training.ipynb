{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training - Indonesian License Plate Detection\n",
    "\n",
    "**Purpose:** Train YOLOv8 model directly on clean Roboflow dataset with optimal baseline parameters.\n",
    "\n",
    "This notebook implements the optimized training approach from CLAUDE.md."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import json\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "# Import YOLOv8\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(\"üì¶ Libraries imported successfully\")\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ CUDA available\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU Memory: {gpu_memory:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  CUDA not available - will use CPU (slower)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths (portable structure with updated root)\n",
    "ROOT_DIR = Path(\"..\").resolve()  # From notebooks/ to license-plate-training/\n",
    "DATASET_PATH = ROOT_DIR / \"dataset\" / \"plat-kendaraan\"\n",
    "MODELS_DIR = ROOT_DIR / \"models\"\n",
    "EXPERIMENTS_DIR = MODELS_DIR / \"experiments\"\n",
    "FINAL_MODELS_DIR = MODELS_DIR / \"final\"\n",
    "RESULTS_DIR = ROOT_DIR / \"results\"\n",
    "\n",
    "# Create directories\n",
    "for directory in [EXPERIMENTS_DIR, FINAL_MODELS_DIR, RESULTS_DIR]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üóÇÔ∏è  Dataset location: {DATASET_PATH}\")\n",
    "print(f\"üìÅ Models directory: {MODELS_DIR}\")\n",
    "\n",
    "# Check if dataset exists\n",
    "if DATASET_PATH.exists():\n",
    "    data_yaml = DATASET_PATH / \"data.yaml\"\n",
    "    if data_yaml.exists():\n",
    "        print(f\"‚úÖ Dataset found with configuration: {data_yaml}\")\n",
    "        \n",
    "        # Load and display config\n",
    "        with open(data_yaml, 'r') as f:\n",
    "            dataset_config = yaml.safe_load(f)\n",
    "        \n",
    "        print(\"\\nüìã Dataset Configuration:\")\n",
    "        for key, value in dataset_config.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        \n",
    "        dataset_ready = True\n",
    "    else:\n",
    "        print(f\"‚ùå data.yaml not found at: {data_yaml}\")\n",
    "        dataset_ready = False\n",
    "else:\n",
    "    print(f\"‚ùå Dataset not found at: {DATASET_PATH}\")\n",
    "    print(\"Please run notebook 01 to download the dataset first.\")\n",
    "    dataset_ready = False\n",
    "\n",
    "# Verify dataset structure\n",
    "if dataset_ready:\n",
    "    print(\"\\nüîç Dataset Structure:\")\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        split_path = DATASET_PATH / split\n",
    "        if split_path.exists():\n",
    "            images = len(list((split_path / 'images').glob('*.jpg')))\n",
    "            labels = len(list((split_path / 'labels').glob('*.txt')))\n",
    "            print(f\"  {split:>5}: {images:>5} images, {labels:>5} labels\")\n",
    "        else:\n",
    "            print(f\"  {split:>5}: ‚ùå Not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Optimal Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Generate experiment name with timestamp for unique identification\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "experiment_name = f\"yolov8n_baseline_{timestamp}\"\n",
    "\n",
    "# Optimal baseline configuration (from CLAUDE.md)\n",
    "training_config = {\n",
    "    # Core parameters\n",
    "    \"data\": str(DATASET_PATH / \"data.yaml\"),\n",
    "    \"epochs\": 100,\n",
    "    \"patience\": 15,      # Early stopping\n",
    "    \"batch\": 16,         # Good balance for 8GB+ GPU  \n",
    "    \"imgsz\": 640,        # Standard YOLO size\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"lr0\": 0.001,        # Conservative learning rate\n",
    "    \"val\": True,\n",
    "    \"save\": True,\n",
    "    \"plots\": True,\n",
    "    \n",
    "    # Output configuration\n",
    "    \"project\": str(EXPERIMENTS_DIR),\n",
    "    \"name\": experiment_name,\n",
    "    \"exist_ok\": True,\n",
    "    \n",
    "    # Performance settings\n",
    "    \"device\": 0 if torch.cuda.is_available() else \"cpu\",\n",
    "    \"workers\": 4 if torch.cuda.is_available() else 2,\n",
    "    \"cache\": False,      # Save memory\n",
    "    \"verbose\": True\n",
    "}\n",
    "\n",
    "# Adjust batch size based on GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    if gpu_memory < 8:\n",
    "        training_config[\"batch\"] = 8\n",
    "        print(f\"‚ö†Ô∏è  Adjusted batch size to 8 for {gpu_memory:.1f} GB GPU\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Using batch size 16 with {gpu_memory:.1f} GB GPU\")\n",
    "else:\n",
    "    training_config[\"batch\"] = 4\n",
    "    training_config[\"workers\"] = 2\n",
    "    print(\"‚ö†Ô∏è  CPU mode: batch size 4, workers 2\")\n",
    "\n",
    "print(\"\\nüéØ Training Configuration:\")\n",
    "print(\"=\" * 30)\n",
    "key_params = [\"epochs\", \"batch\", \"imgsz\", \"optimizer\", \"lr0\", \"patience\", \"device\"]\n",
    "for key in key_params:\n",
    "    print(f\"{key:>10}: {training_config[key]}\")\n",
    "\n",
    "print(f\"\\nüöÄ Experiment: {experiment_name}\")\n",
    "print(f\"üìä Results will be saved to: {EXPERIMENTS_DIR / experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load YOLOv8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_ready:\n",
    "    print(\"ü§ñ Loading YOLOv8n model...\")\n",
    "    \n",
    "    try:\n",
    "        # Load pre-trained YOLOv8 nano model\n",
    "        model = YOLO('yolov8n.pt')\n",
    "        print(\"‚úÖ YOLOv8n model loaded successfully\")\n",
    "        \n",
    "        # Display model info\n",
    "        print(\"\\nüìã Model Information:\")\n",
    "        model.info(verbose=False)\n",
    "        \n",
    "        model_ready = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load model: {e}\")\n",
    "        model_ready = False\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping model loading - dataset not ready\")\n",
    "    model_ready = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_ready and model_ready:\n",
    "    print(\"üöÄ Starting YOLOv8 training...\")\n",
    "    print(f\"Target: mAP@0.5 > 0.85\")\n",
    "    print(f\"Training will stop early if no improvement for {training_config['patience']} epochs\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Start training\n",
    "        results = model.train(**training_config)\n",
    "        \n",
    "        print(\"\\nüéâ Training completed successfully!\")\n",
    "        print(f\"üìä Results saved to: {EXPERIMENTS_DIR / experiment_name}\")\n",
    "        \n",
    "        training_success = True\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚èπÔ∏è  Training interrupted by user\")\n",
    "        training_success = False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Training failed: {e}\")\n",
    "        print(\"\\nüîß Troubleshooting tips:\")\n",
    "        print(\"  ‚Ä¢ Reduce batch size if out of memory\")\n",
    "        print(\"  ‚Ä¢ Check dataset paths in data.yaml\")\n",
    "        print(\"  ‚Ä¢ Verify GPU/CUDA installation\")\n",
    "        training_success = False\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Cannot start training:\")\n",
    "    if not dataset_ready:\n",
    "        print(\"  ‚Ä¢ Dataset not ready - run cells above\")\n",
    "    if not model_ready:\n",
    "        print(\"  ‚Ä¢ Model not loaded - check previous cell\")\n",
    "    training_success = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'training_success' in locals() and training_success:\n",
    "    print(\"üìä Analyzing training results...\")\n",
    "    \n",
    "    # Find experiment directory\n",
    "    exp_dir = EXPERIMENTS_DIR / experiment_name\n",
    "    \n",
    "    if exp_dir.exists():\n",
    "        print(f\"‚úÖ Experiment directory: {exp_dir}\")\n",
    "        \n",
    "        # Check for results files\n",
    "        results_csv = exp_dir / \"results.csv\"\n",
    "        if results_csv.exists():\n",
    "            import pandas as pd\n",
    "            \n",
    "            # Load training metrics\n",
    "            df = pd.read_csv(results_csv)\n",
    "            print(f\"\\nüìà Training completed in {len(df)} epochs\")\n",
    "            \n",
    "            # Extract key metrics from final epoch\n",
    "            final_metrics = df.iloc[-1]\n",
    "            \n",
    "            print(\"\\nüéØ Final Performance:\")\n",
    "            print(\"=\" * 25)\n",
    "            \n",
    "            # Key metrics to display\n",
    "            metric_names = {\n",
    "                'metrics/mAP50(B)': 'mAP@0.5',\n",
    "                'metrics/mAP50-95(B)': 'mAP@0.5:0.95', \n",
    "                'metrics/precision(B)': 'Precision',\n",
    "                'metrics/recall(B)': 'Recall',\n",
    "                'train/box_loss': 'Box Loss',\n",
    "                'val/box_loss': 'Val Box Loss'\n",
    "            }\n",
    "            \n",
    "            for col, name in metric_names.items():\n",
    "                if col in df.columns:\n",
    "                    value = final_metrics[col]\n",
    "                    if 'loss' in col.lower():\n",
    "                        print(f\"{name:>12}: {value:.4f}\")\n",
    "                    else:\n",
    "                        print(f\"{name:>12}: {value:.3f}\")\n",
    "            \n",
    "            # Check if target mAP@0.5 > 0.85 was achieved\n",
    "            map50_col = 'metrics/mAP50(B)'\n",
    "            if map50_col in df.columns:\n",
    "                final_map50 = final_metrics[map50_col]\n",
    "                target_map50 = 0.85\n",
    "                \n",
    "                print(f\"\\nüéØ Performance vs Target:\")\n",
    "                print(f\"Final mAP@0.5: {final_map50:.3f}\")\n",
    "                print(f\"Target mAP@0.5: {target_map50:.3f}\")\n",
    "                \n",
    "                if final_map50 >= target_map50:\n",
    "                    print(\"‚úÖ TARGET ACHIEVED! Model ready for production.\")\n",
    "                else:\n",
    "                    gap = target_map50 - final_map50\n",
    "                    print(f\"‚ö†Ô∏è  Target not reached (gap: {gap:.3f})\")\n",
    "                    print(\"üí° Consider: upgrade to yolov8s, increase epochs, or tune hyperparameters\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  results.csv not found\")\n",
    "            \n",
    "        # List generated files\n",
    "        print(f\"\\nüìÅ Generated files in {exp_dir}:\")\n",
    "        for item in exp_dir.rglob('*'):\n",
    "            if item.is_file():\n",
    "                rel_path = item.relative_to(exp_dir)\n",
    "                print(f\"  üìÑ {rel_path}\")\n",
    "                \n",
    "    else:\n",
    "        print(f\"‚ùå Experiment directory not found: {exp_dir}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No training results to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Best Model for Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'training_success' in locals() and training_success:\n",
    "    print(\"üì¶ Exporting best model for production...\")\n",
    "    \n",
    "    exp_dir = EXPERIMENTS_DIR / experiment_name\n",
    "    weights_dir = exp_dir / \"weights\"\n",
    "    best_weights = weights_dir / \"best.pt\"\n",
    "    \n",
    "    if best_weights.exists():\n",
    "        # Copy best model to final models directory\n",
    "        final_model_name = f\"yolov8n_indonesian_plates_{timestamp}.pt\"\n",
    "        final_model_path = FINAL_MODELS_DIR / final_model_name\n",
    "        \n",
    "        shutil.copy2(best_weights, final_model_path)\n",
    "        print(f\"‚úÖ Model saved as: {final_model_path}\")\n",
    "        \n",
    "        # Create best_model.pt link (as specified in CLAUDE.md)\n",
    "        best_model_link = FINAL_MODELS_DIR / \"best_model.pt\"\n",
    "        if best_model_link.exists():\n",
    "            best_model_link.unlink()\n",
    "        \n",
    "        shutil.copy2(final_model_path, best_model_link)\n",
    "        print(f\"‚úÖ Created production link: {best_model_link}\")\n",
    "        \n",
    "        # Check model size (target < 50MB from CLAUDE.md)\n",
    "        model_size_mb = final_model_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"üìè Model size: {model_size_mb:.1f} MB\")\n",
    "        \n",
    "        if model_size_mb < 50:\n",
    "            print(\"‚úÖ Model size meets deployment requirement (< 50MB)\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Model exceeds 50MB target for deployment\")\n",
    "        \n",
    "        # Test model loading\n",
    "        print(\"\\nüß™ Testing model loading...\")\n",
    "        try:\n",
    "            test_model = YOLO(str(final_model_path))\n",
    "            print(\"‚úÖ Model loads successfully\")\n",
    "            \n",
    "            # Model info\n",
    "            print(f\"Model classes: {test_model.names}\")\n",
    "            print(f\"Model device: {test_model.device}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Model loading failed: {e}\")\n",
    "        \n",
    "        print(f\"\\nüöÄ Model ready for production integration!\")\n",
    "        print(f\"Next: Run notebook 05_evaluation_export.ipynb for detailed evaluation\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå Best weights not found at: {best_weights}\")\n",
    "        print(\"Check if training completed successfully\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No trained model to export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### ‚úÖ Training Configuration Used:\n",
    "- **Model**: YOLOv8n (optimized for speed/size balance)\n",
    "- **Epochs**: 100 with early stopping (patience=15)\n",
    "- **Batch Size**: 16 (GPU) / 8 (low memory) / 4 (CPU)\n",
    "- **Image Size**: 640√ó640 (standard YOLO)\n",
    "- **Optimizer**: AdamW with lr=0.001\n",
    "\n",
    "### üéØ Performance Targets (CLAUDE.md):\n",
    "- **Accuracy**: mAP@0.5 > 0.85 ‚úÖ/‚ö†Ô∏è\n",
    "- **Speed**: < 100ms per image (GPU inference)\n",
    "- **Model Size**: < 50MB for deployment\n",
    "- **Confidence**: >= 0.3 threshold\n",
    "\n",
    "### üí° If Target Not Met - Tuning Options:\n",
    "1. **Model Upgrade**: yolov8n ‚Üí yolov8s ‚Üí yolov8m\n",
    "2. **Batch Size**: 8/16/32 (GPU memory dependent)\n",
    "3. **Image Size**: 640 ‚Üí 832 ‚Üí 1024 (accuracy vs speed)\n",
    "4. **Learning Rate**: 0.0005 ‚Üí 0.002 (fine-tuning)\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "1. **Check training results above**\n",
    "2. **Run notebook 05_evaluation_export.ipynb for detailed evaluation**\n",
    "3. **Test model on sample images**\n",
    "4. **Integrate with production system**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
