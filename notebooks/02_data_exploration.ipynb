{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration - Indonesian License Plate Dataset\n",
    "\n",
    "This notebook analyzes the Indonesian license plate dataset characteristics and quality.\n",
    "\n",
    "## Tasks:\n",
    "- [ ] Load and examine dataset structure\n",
    "- [ ] Visualize sample images with annotations\n",
    "- [ ] Analyze Indonesian license plate patterns\n",
    "- [ ] Check annotation quality and consistency\n",
    "- [ ] Identify data issues (missing labels, corrupt images)\n",
    "- [ ] Generate statistics: image sizes, aspect ratios, label distributions\n",
    "- [ ] Create data quality report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import yaml\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Path Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths (adjust based on your download structure)\n",
    "BASE_DIR = Path(\"..\")\n",
    "DATASET_RAW = BASE_DIR / \"dataset\" / \"raw\"\n",
    "\n",
    "# Common dataset folder names from Roboflow\n",
    "possible_dataset_folders = [\n",
    "    \"Indonesia-License-Plate-2\",\n",
    "    \"indonesia-license-plate-iqrtj\", \n",
    "    \"Indonesia-License-Plate\",\n",
    "    \"dataset\"\n",
    "]\n",
    "\n",
    "# Find the actual dataset folder\n",
    "DATASET_PATH = None\n",
    "if DATASET_RAW.exists():\n",
    "    for folder in possible_dataset_folders:\n",
    "        potential_path = DATASET_RAW / folder\n",
    "        if potential_path.exists():\n",
    "            DATASET_PATH = potential_path\n",
    "            break\n",
    "    \n",
    "    # If no specific folder found, check if files are directly in raw\n",
    "    if DATASET_PATH is None:\n",
    "        yaml_files = list(DATASET_RAW.glob(\"*.yaml\"))\n",
    "        if yaml_files:\n",
    "            DATASET_PATH = DATASET_RAW\n",
    "\n",
    "print(f\"Dataset raw directory: {DATASET_RAW}\")\n",
    "print(f\"Dataset path: {DATASET_PATH}\")\n",
    "print(f\"Dataset exists: {DATASET_PATH.exists() if DATASET_PATH else False}\")\n",
    "\n",
    "if DATASET_PATH and DATASET_PATH.exists():\n",
    "    print(\"\\nDataset contents:\")\n",
    "    for item in DATASET_PATH.iterdir():\n",
    "        if item.is_dir():\n",
    "            file_count = len(list(item.rglob(\"*.*\")))\n",
    "            print(f\"  üìÅ {item.name}/ ({file_count} files)\")\n",
    "        else:\n",
    "            print(f\"  üìÑ {item.name}\")\nelse:\n",
    "    print(\"\\n‚ö†Ô∏è  Dataset not found. Please run notebook 01 to download the dataset first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YAML configuration if available\n",
    "dataset_config = None\n",
    "yaml_file = None\n",
    "\n",
    "if DATASET_PATH and DATASET_PATH.exists():\n",
    "    # Look for YAML files\n",
    "    yaml_files = list(DATASET_PATH.glob(\"*.yaml\")) + list(DATASET_PATH.glob(\"data.yaml\"))\n",
    "    \n",
    "    if yaml_files:\n",
    "        yaml_file = yaml_files[0]\n",
    "        print(f\"Found YAML config: {yaml_file.name}\")\n",
    "        \n",
    "        with open(yaml_file, 'r') as f:\n",
    "            dataset_config = yaml.safe_load(f)\n",
    "        \n",
    "        print(\"\\nDataset Configuration:\")\n",
    "        print(\"=\" * 30)\n",
    "        for key, value in dataset_config.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "    else:\n",
    "        print(\"No YAML configuration file found\")\n",
    "        \n",
    "        # Try to infer structure\n",
    "        splits = ['train', 'valid', 'test', 'val']\n",
    "        found_splits = []\n",
    "        for split in splits:\n",
    "            split_path = DATASET_PATH / split\n",
    "            if split_path.exists():\n",
    "                found_splits.append(split)\n",
    "        \n",
    "        if found_splits:\n",
    "            print(f\"Inferred dataset splits: {found_splits}\")\n",
    "            \n",
    "            # Create basic config\n",
    "            dataset_config = {\n",
    "                'path': str(DATASET_PATH),\n",
    "                'train': found_splits[0] if 'train' in found_splits else found_splits[0],\n",
    "                'val': 'valid' if 'valid' in found_splits else ('val' if 'val' in found_splits else found_splits[-1]),\n",
    "                'test': 'test' if 'test' in found_splits else None,\n",
    "                'names': ['plate', 'vehicle']  # Assumed based on dataset research\n",
    "            }\nelse:\n",
    "    print(\"Dataset path not available for configuration loading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset_structure(dataset_path):\n",
    "    \"\"\"Analyze the structure and content of the dataset\"\"\"\n",
    "    if not dataset_path or not dataset_path.exists():\n",
    "        print(\"Dataset path not available\")\n",
    "        return None\n",
    "    \n",
    "    analysis = {\n",
    "        'splits': {},\n",
    "        'total_images': 0,\n",
    "        'total_labels': 0,\n",
    "        'image_formats': Counter(),\n",
    "        'issues': []\n",
    "    }\n",
    "    \n",
    "    # Define possible split names\n",
    "    split_names = ['train', 'valid', 'val', 'test']\n",
    "    \n",
    "    for split_name in split_names:\n",
    "        split_path = dataset_path / split_name\n",
    "        if not split_path.exists():\n",
    "            continue\n",
    "            \n",
    "        images_path = split_path / 'images'\n",
    "        labels_path = split_path / 'labels'\n",
    "        \n",
    "        split_info = {\n",
    "            'images': 0,\n",
    "            'labels': 0,\n",
    "            'image_files': [],\n",
    "            'label_files': [],\n",
    "            'missing_labels': [],\n",
    "            'missing_images': []\n",
    "        }\n",
    "        \n",
    "        # Count images\n",
    "        if images_path.exists():\n",
    "            image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "            for ext in image_extensions:\n",
    "                files = list(images_path.glob(f'*{ext}')) + list(images_path.glob(f'*{ext.upper()}'))\n",
    "                split_info['image_files'].extend(files)\n",
    "                \n",
    "                # Count formats\n",
    "                for file in files:\n",
    "                    analysis['image_formats'][ext.lower()] += 1\n",
    "        \n",
    "        split_info['images'] = len(split_info['image_files'])\n",
    "        \n",
    "        # Count labels\n",
    "        if labels_path.exists():\n",
    "            label_files = list(labels_path.glob('*.txt'))\n",
    "            split_info['label_files'] = label_files\n",
    "            split_info['labels'] = len(label_files)\n",
    "        \n",
    "        # Check for missing pairs\n",
    "        image_stems = {f.stem for f in split_info['image_files']}\n",
    "        label_stems = {f.stem for f in split_info['label_files']}\n",
    "        \n",
    "        split_info['missing_labels'] = list(image_stems - label_stems)\n",
    "        split_info['missing_images'] = list(label_stems - image_stems)\n",
    "        \n",
    "        if split_info['missing_labels']:\n",
    "            analysis['issues'].append(f\"{split_name}: {len(split_info['missing_labels'])} images without labels\")\n",
    "        \n",
    "        if split_info['missing_images']:\n",
    "            analysis['issues'].append(f\"{split_name}: {len(split_info['missing_images'])} labels without images\")\n",
    "        \n",
    "        analysis['splits'][split_name] = split_info\n",
    "        analysis['total_images'] += split_info['images']\n",
    "        analysis['total_labels'] += split_info['labels']\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Run analysis\n",
    "structure_analysis = analyze_dataset_structure(DATASET_PATH)\n",
    "\n",
    "if structure_analysis:\n",
    "    print(\"üìä Dataset Structure Analysis\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Total Images: {structure_analysis['total_images']}\")\n",
    "    print(f\"Total Labels: {structure_analysis['total_labels']}\")\n",
    "    print(f\"Image Formats: {dict(structure_analysis['image_formats'])}\")\n",
    "    \n",
    "    print(\"\\nüìÅ Split Breakdown:\")\n",
    "    for split_name, split_info in structure_analysis['splits'].items():\n",
    "        print(f\"  {split_name.upper()}:\")\n",
    "        print(f\"    Images: {split_info['images']}\")\n",
    "        print(f\"    Labels: {split_info['labels']}\")\n",
    "        print(f\"    Match Rate: {split_info['labels']/split_info['images']*100:.1f}%\" if split_info['images'] > 0 else \"    Match Rate: N/A\")\n",
    "    \n",
    "    if structure_analysis['issues']:\n",
    "        print(\"\\n‚ö†Ô∏è  Issues Found:\")\n",
    "        for issue in structure_analysis['issues']:\n",
    "            print(f\"  - {issue}\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ No structural issues found\")\nelse:\n",
    "    print(\"Cannot analyze dataset structure - dataset not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sample Image Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yolo_annotations(label_file, img_width, img_height):\n",
    "    \"\"\"Load YOLO format annotations and convert to pixel coordinates\"\"\"\n",
    "    annotations = []\n",
    "    \n",
    "    if not label_file.exists():\n",
    "        return annotations\n",
    "    \n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 5:\n",
    "                class_id = int(parts[0])\n",
    "                x_center = float(parts[1])\n",
    "                y_center = float(parts[2])\n",
    "                width = float(parts[3])\n",
    "                height = float(parts[4])\n",
    "                \n",
    "                # Convert to pixel coordinates\n",
    "                x1 = int((x_center - width/2) * img_width)\n",
    "                y1 = int((y_center - height/2) * img_height)\n",
    "                x2 = int((x_center + width/2) * img_width)\n",
    "                y2 = int((y_center + height/2) * img_height)\n",
    "                \n",
    "                annotations.append({\n",
    "                    'class_id': class_id,\n",
    "                    'bbox': [x1, y1, x2, y2],\n",
    "                    'center': [x_center, y_center],\n",
    "                    'size': [width, height]\n",
    "                })\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "def visualize_sample_images(dataset_path, dataset_config, num_samples=6):\n",
    "    \"\"\"Visualize sample images with their annotations\"\"\"\n",
    "    if not dataset_path or not dataset_path.exists():\n",
    "        print(\"Dataset not available for visualization\")\n",
    "        return\n",
    "    \n",
    "    # Get class names\n",
    "    class_names = dataset_config.get('names', ['class_0', 'class_1']) if dataset_config else ['plate', 'vehicle']\n",
    "    colors = ['red', 'blue', 'green', 'yellow', 'purple', 'orange']\n",
    "    \n",
    "    # Find images from train split\n",
    "    train_split = 'train'\n",
    "    if dataset_config and 'train' in dataset_config:\n",
    "        train_split = dataset_config['train']\n",
    "    \n",
    "    images_path = dataset_path / train_split / 'images'\n",
    "    labels_path = dataset_path / train_split / 'labels'\n",
    "    \n",
    "    if not images_path.exists():\n",
    "        print(f\"Images path not found: {images_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get sample images\n",
    "    image_files = list(images_path.glob('*.jpg')) + list(images_path.glob('*.png'))\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        print(\"No image files found\")\n",
    "        return\n",
    "    \n",
    "    # Randomly sample images\n",
    "    np.random.seed(42)\n",
    "    sample_files = np.random.choice(image_files, min(num_samples, len(image_files)), replace=False)\n",
    "    \n",
    "    # Create subplot\n",
    "    rows = 2\n",
    "    cols = 3\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, img_file in enumerate(sample_files):\n",
    "        if idx >= len(axes):\n",
    "            break\n",
    "            \n",
    "        # Load image\n",
    "        img = cv2.imread(str(img_file))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_height, img_width = img.shape[:2]\n",
    "        \n",
    "        # Load corresponding label\n",
    "        label_file = labels_path / f\"{img_file.stem}.txt\"\n",
    "        annotations = load_yolo_annotations(label_file, img_width, img_height)\n",
    "        \n",
    "        # Draw annotations\n",
    "        img_annotated = img.copy()\n",
    "        for ann in annotations:\n",
    "            x1, y1, x2, y2 = ann['bbox']\n",
    "            class_id = ann['class_id']\n",
    "            \n",
    "            # Draw bounding box\n",
    "            color = colors[class_id % len(colors)]\n",
    "            cv2.rectangle(img_annotated, (x1, y1), (x2, y2), \n",
    "                         plt.colors.to_rgb(color), 2)\n",
    "            \n",
    "            # Add class label\n",
    "            class_name = class_names[class_id] if class_id < len(class_names) else f'class_{class_id}'\n",
    "            cv2.putText(img_annotated, class_name, (x1, y1-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, plt.colors.to_rgb(color), 2)\n",
    "        \n",
    "        # Display\n",
    "        axes[idx].imshow(img_annotated)\n",
    "        axes[idx].set_title(f\"{img_file.name}\\n{len(annotations)} objects\", fontsize=10)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(len(sample_files), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Sample Images with Annotations', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nSample Analysis:\")\n",
    "    print(f\"Displaying {len(sample_files)} sample images\")\n",
    "    print(f\"Class names: {class_names}\")\n",
    "\n",
    "# Run visualization\nvisualize_sample_images(DATASET_PATH, dataset_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Image Statistics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_statistics(dataset_path, max_samples=200):\n",
    "    \"\"\"Analyze image dimensions, aspect ratios, and file sizes\"\"\"\n",
    "    if not dataset_path or not dataset_path.exists():\n",
    "        print(\"Dataset not available for image analysis\")\n",
    "        return None\n",
    "    \n",
    "    stats = {\n",
    "        'widths': [],\n",
    "        'heights': [],\n",
    "        'aspect_ratios': [],\n",
    "        'file_sizes': [],\n",
    "        'areas': [],\n",
    "        'splits': {}\n",
    "    }\n",
    "    \n",
    "    split_names = ['train', 'valid', 'val', 'test']\n",
    "    \n",
    "    for split_name in split_names:\n",
    "        images_path = dataset_path / split_name / 'images'\n",
    "        if not images_path.exists():\n",
    "            continue\n",
    "        \n",
    "        image_files = list(images_path.glob('*.jpg')) + list(images_path.glob('*.png'))\n",
    "        \n",
    "        # Sample images if too many\n",
    "        if len(image_files) > max_samples:\n",
    "            np.random.seed(42)\n",
    "            image_files = np.random.choice(image_files, max_samples, replace=False)\n",
    "        \n",
    "        split_stats = {\n",
    "            'widths': [],\n",
    "            'heights': [],\n",
    "            'aspect_ratios': [],\n",
    "            'file_sizes': [],\n",
    "            'areas': []\n",
    "        }\n",
    "        \n",
    "        print(f\"Analyzing {len(image_files)} images from {split_name} split...\")\n",
    "        \n",
    "        for img_file in image_files:\n",
    "            try:\n",
    "                # Get file size\n",
    "                file_size = img_file.stat().st_size / 1024  # KB\n",
    "                \n",
    "                # Get image dimensions\n",
    "                with Image.open(img_file) as img:\n",
    "                    width, height = img.size\n",
    "                    aspect_ratio = width / height\n",
    "                    area = width * height\n",
    "                    \n",
    "                    # Store in both overall and split stats\n",
    "                    for storage in [stats, split_stats]:\n",
    "                        storage['widths'].append(width)\n",
    "                        storage['heights'].append(height)\n",
    "                        storage['aspect_ratios'].append(aspect_ratio)\n",
    "                        storage['file_sizes'].append(file_size)\n",
    "                        storage['areas'].append(area)\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_file}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        stats['splits'][split_name] = split_stats\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Run image statistics analysis\n",
    "image_stats = analyze_image_statistics(DATASET_PATH)\n",
    "\n",
    "if image_stats and len(image_stats['widths']) > 0:\n",
    "    print(\"\\nüìê Image Statistics Summary\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Overall statistics\n",
    "    print(f\"Total analyzed images: {len(image_stats['widths'])}\")\n",
    "    print(f\"\\nDimensions:\")\n",
    "    print(f\"  Width  - Min: {min(image_stats['widths'])}, Max: {max(image_stats['widths'])}, Avg: {np.mean(image_stats['widths']):.0f}\")\n",
    "    print(f\"  Height - Min: {min(image_stats['heights'])}, Max: {max(image_stats['heights'])}, Avg: {np.mean(image_stats['heights']):.0f}\")\n",
    "    \n",
    "    print(f\"\\nAspect Ratios:\")\n",
    "    print(f\"  Min: {min(image_stats['aspect_ratios']):.2f}, Max: {max(image_stats['aspect_ratios']):.2f}, Avg: {np.mean(image_stats['aspect_ratios']):.2f}\")\n",
    "    \n",
    "    print(f\"\\nFile Sizes (KB):\")\n",
    "    print(f\"  Min: {min(image_stats['file_sizes']):.1f}, Max: {max(image_stats['file_sizes']):.1f}, Avg: {np.mean(image_stats['file_sizes']):.1f}\")\n",
    "    \n",
    "    # Most common dimensions\n",
    "    dimensions = [(w, h) for w, h in zip(image_stats['widths'], image_stats['heights'])]\n",
    "    dim_counter = Counter(dimensions)\n",
    "    print(f\"\\nMost common dimensions:\")\n",
    "    for (w, h), count in dim_counter.most_common(5):\n",
    "        print(f\"  {w}x{h}: {count} images ({count/len(dimensions)*100:.1f}%)\")\nelse:\n",
    "    print(\"No image statistics available - dataset not loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Visualization Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_statistics_plots(image_stats):\n",
    "    \"\"\"Create comprehensive plots for image statistics\"\"\"\n",
    "    if not image_stats or len(image_stats['widths']) == 0:\n",
    "        print(\"No data available for plotting\")\n",
    "        return\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # 1. Image dimensions scatter plot\n",
    "    axes[0,0].scatter(image_stats['widths'], image_stats['heights'], alpha=0.6, s=20)\n",
    "    axes[0,0].set_xlabel('Width (pixels)')\n",
    "    axes[0,0].set_ylabel('Height (pixels)')\n",
    "    axes[0,0].set_title('Image Dimensions Distribution')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Aspect ratio histogram\n",
    "    axes[0,1].hist(image_stats['aspect_ratios'], bins=30, alpha=0.7, color='skyblue')\n",
    "    axes[0,1].axvline(np.mean(image_stats['aspect_ratios']), color='red', linestyle='--', label='Mean')\n",
    "    axes[0,1].set_xlabel('Aspect Ratio (W/H)')\n",
    "    axes[0,1].set_ylabel('Frequency')\n",
    "    axes[0,1].set_title('Aspect Ratio Distribution')\n",
    "    axes[0,1].legend()\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. File size histogram\n",
    "    axes[0,2].hist(image_stats['file_sizes'], bins=30, alpha=0.7, color='lightgreen')\n",
    "    axes[0,2].axvline(np.mean(image_stats['file_sizes']), color='red', linestyle='--', label='Mean')\n",
    "    axes[0,2].set_xlabel('File Size (KB)')\n",
    "    axes[0,2].set_ylabel('Frequency')\n",
    "    axes[0,2].set_title('File Size Distribution')\n",
    "    axes[0,2].legend()\n",
    "    axes[0,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Width distribution by split\n",
    "    if len(image_stats['splits']) > 1:\n",
    "        for split_name, split_stats in image_stats['splits'].items():\n",
    "            if len(split_stats['widths']) > 0:\n",
    "                axes[1,0].hist(split_stats['widths'], bins=20, alpha=0.5, label=split_name)\n",
    "        axes[1,0].set_xlabel('Width (pixels)')\n",
    "        axes[1,0].set_ylabel('Frequency')\n",
    "        axes[1,0].set_title('Width Distribution by Split')\n",
    "        axes[1,0].legend()\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[1,0].hist(image_stats['widths'], bins=20, alpha=0.7, color='orange')\n",
    "        axes[1,0].set_xlabel('Width (pixels)')\n",
    "        axes[1,0].set_ylabel('Frequency')\n",
    "        axes[1,0].set_title('Width Distribution')\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Height distribution by split\n",
    "    if len(image_stats['splits']) > 1:\n",
    "        for split_name, split_stats in image_stats['splits'].items():\n",
    "            if len(split_stats['heights']) > 0:\n",
    "                axes[1,1].hist(split_stats['heights'], bins=20, alpha=0.5, label=split_name)\n",
    "        axes[1,1].set_xlabel('Height (pixels)')\n",
    "        axes[1,1].set_ylabel('Frequency')\n",
    "        axes[1,1].set_title('Height Distribution by Split')\n",
    "        axes[1,1].legend()\n",
    "        axes[1,1].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[1,1].hist(image_stats['heights'], bins=20, alpha=0.7, color='coral')\n",
    "        axes[1,1].set_xlabel('Height (pixels)')\n",
    "        axes[1,1].set_ylabel('Frequency')\n",
    "        axes[1,1].set_title('Height Distribution')\n",
    "        axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Areas vs aspect ratio\n",
    "    areas_mb = [area / 1e6 for area in image_stats['areas']]  # Convert to megapixels\n",
    "    axes[1,2].scatter(image_stats['aspect_ratios'], areas_mb, alpha=0.6, s=20, color='purple')\n",
    "    axes[1,2].set_xlabel('Aspect Ratio')\n",
    "    axes[1,2].set_ylabel('Area (Megapixels)')\n",
    "    axes[1,2].set_title('Image Area vs Aspect Ratio')\n",
    "    axes[1,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save plots\n",
    "    plots_dir = Path(\"../results/plots\")\n",
    "    plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(plots_dir / \"image_statistics_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nPlots saved to: {plots_dir / 'image_statistics_analysis.png'}\")\n",
    "\n",
    "# Create plots\nif image_stats:\n",
    "    create_statistics_plots(image_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Annotation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_annotations(dataset_path, dataset_config):\n",
    "    \"\"\"Analyze YOLO annotations for class distribution and bbox statistics\"\"\"\n",
    "    if not dataset_path or not dataset_path.exists():\n",
    "        print(\"Dataset not available for annotation analysis\")\n",
    "        return None\n",
    "    \n",
    "    class_names = dataset_config.get('names', ['plate', 'vehicle']) if dataset_config else ['plate', 'vehicle']\n",
    "    \n",
    "    annotation_stats = {\n",
    "        'class_distribution': Counter(),\n",
    "        'bbox_widths': [],\n",
    "        'bbox_heights': [],\n",
    "        'bbox_areas': [],\n",
    "        'center_x': [],\n",
    "        'center_y': [],\n",
    "        'objects_per_image': [],\n",
    "        'splits': {}\n",
    "    }\n",
    "    \n",
    "    split_names = ['train', 'valid', 'val', 'test']\n",
    "    \n",
    "    for split_name in split_names:\n",
    "        labels_path = dataset_path / split_name / 'labels'\n",
    "        if not labels_path.exists():\n",
    "            continue\n",
    "        \n",
    "        label_files = list(labels_path.glob('*.txt'))\n",
    "        \n",
    "        split_stats = {\n",
    "            'class_distribution': Counter(),\n",
    "            'bbox_widths': [],\n",
    "            'bbox_heights': [],\n",
    "            'bbox_areas': [],\n",
    "            'center_x': [],\n",
    "            'center_y': [],\n",
    "            'objects_per_image': []\n",
    "        }\n",
    "        \n",
    "        print(f\"Analyzing {len(label_files)} label files from {split_name} split...\")\n",
    "        \n",
    "        for label_file in label_files:\n",
    "            objects_in_image = 0\n",
    "            \n",
    "            try:\n",
    "                with open(label_file, 'r') as f:\n",
    "                    for line in f:\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) >= 5:\n",
    "                            class_id = int(parts[0])\n",
    "                            x_center = float(parts[1])\n",
    "                            y_center = float(parts[2])\n",
    "                            width = float(parts[3])\n",
    "                            height = float(parts[4])\n",
    "                            area = width * height\n",
    "                            \n",
    "                            objects_in_image += 1\n",
    "                            \n",
    "                            # Store in both overall and split stats\n",
    "                            for storage in [annotation_stats, split_stats]:\n",
    "                                storage['class_distribution'][class_id] += 1\n",
    "                                storage['bbox_widths'].append(width)\n",
    "                                storage['bbox_heights'].append(height)\n",
    "                                storage['bbox_areas'].append(area)\n",
    "                                storage['center_x'].append(x_center)\n",
    "                                storage['center_y'].append(y_center)\n",
    "                \n",
    "                # Store objects per image\n",
    "                for storage in [annotation_stats, split_stats]:\n",
    "                    storage['objects_per_image'].append(objects_in_image)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {label_file}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        annotation_stats['splits'][split_name] = split_stats\n",
    "    \n",
    "    return annotation_stats, class_names\n",
    "\n",
    "# Run annotation analysis\nannotation_stats, class_names = analyze_annotations(DATASET_PATH, dataset_config)\n",
    "\n",
    "if annotation_stats and len(annotation_stats['bbox_widths']) > 0:\n",
    "    print(\"\\nüè∑Ô∏è  Annotation Statistics Summary\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Class distribution\n",
    "    total_objects = sum(annotation_stats['class_distribution'].values())\n",
    "    print(f\"Total annotated objects: {total_objects}\")\n",
    "    print(f\"\\nClass Distribution:\")\n",
    "    for class_id, count in annotation_stats['class_distribution'].items():\n",
    "        class_name = class_names[class_id] if class_id < len(class_names) else f'class_{class_id}'\n",
    "        percentage = count / total_objects * 100\n",
    "        print(f\"  {class_name} (id={class_id}): {count} objects ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Bounding box statistics (normalized coordinates)\n",
    "    print(f\"\\nBounding Box Statistics (normalized):\")\n",
    "    print(f\"  Width  - Min: {min(annotation_stats['bbox_widths']):.3f}, Max: {max(annotation_stats['bbox_widths']):.3f}, Avg: {np.mean(annotation_stats['bbox_widths']):.3f}\")\n",
    "    print(f\"  Height - Min: {min(annotation_stats['bbox_heights']):.3f}, Max: {max(annotation_stats['bbox_heights']):.3f}, Avg: {np.mean(annotation_stats['bbox_heights']):.3f}\")\n",
    "    print(f\"  Area   - Min: {min(annotation_stats['bbox_areas']):.4f}, Max: {max(annotation_stats['bbox_areas']):.4f}, Avg: {np.mean(annotation_stats['bbox_areas']):.4f}\")\n",
    "    \n",
    "    # Objects per image\n",
    "    print(f\"\\nObjects per Image:\")\n",
    "    print(f\"  Min: {min(annotation_stats['objects_per_image'])}, Max: {max(annotation_stats['objects_per_image'])}, Avg: {np.mean(annotation_stats['objects_per_image']):.2f}\")\n",
    "    \n",
    "    # Most common object counts\n",
    "    obj_counter = Counter(annotation_stats['objects_per_image'])\n",
    "    print(f\"\\nMost common object counts per image:\")\n",
    "    for count, freq in obj_counter.most_common(5):\n",
    "        print(f\"  {count} objects: {freq} images ({freq/len(annotation_stats['objects_per_image'])*100:.1f}%)\")\nelse:\n",
    "    print(\"No annotation statistics available - dataset not loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create Annotation Visualization Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annotation_plots(annotation_stats, class_names):\n",
    "    \"\"\"Create visualization plots for annotation analysis\"\"\"\n",
    "    if not annotation_stats or len(annotation_stats['bbox_widths']) == 0:\n",
    "        print(\"No annotation data available for plotting\")\n",
    "        return\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # 1. Class distribution pie chart\n",
    "    class_counts = []\n",
    "    class_labels = []\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(annotation_stats['class_distribution'])))\n",
    "    \n",
    "    for class_id, count in annotation_stats['class_distribution'].items():\n",
    "        class_name = class_names[class_id] if class_id < len(class_names) else f'class_{class_id}'\n",
    "        class_counts.append(count)\n",
    "        class_labels.append(f'{class_name}\\n({count})')\n",
    "    \n",
    "    axes[0,0].pie(class_counts, labels=class_labels, autopct='%1.1f%%', colors=colors)\n",
    "    axes[0,0].set_title('Class Distribution')\n",
    "    \n",
    "    # 2. Bounding box width distribution\n",
    "    axes[0,1].hist(annotation_stats['bbox_widths'], bins=30, alpha=0.7, color='skyblue')\n",
    "    axes[0,1].axvline(np.mean(annotation_stats['bbox_widths']), color='red', linestyle='--', label='Mean')\n",
    "    axes[0,1].set_xlabel('Normalized Width')\n",
    "    axes[0,1].set_ylabel('Frequency')\n",
    "    axes[0,1].set_title('Bounding Box Width Distribution')\n",
    "    axes[0,1].legend()\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Bounding box height distribution\n",
    "    axes[0,2].hist(annotation_stats['bbox_heights'], bins=30, alpha=0.7, color='lightgreen')\n",
    "    axes[0,2].axvline(np.mean(annotation_stats['bbox_heights']), color='red', linestyle='--', label='Mean')\n",
    "    axes[0,2].set_xlabel('Normalized Height')\n",
    "    axes[0,2].set_ylabel('Frequency')\n",
    "    axes[0,2].set_title('Bounding Box Height Distribution')\n",
    "    axes[0,2].legend()\n",
    "    axes[0,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Objects per image distribution\n",
    "    obj_counts = list(range(max(annotation_stats['objects_per_image'])+1))\n",
    "    obj_frequencies = [annotation_stats['objects_per_image'].count(i) for i in obj_counts]\n",
    "    \n",
    "    axes[1,0].bar(obj_counts, obj_frequencies, alpha=0.7, color='orange')\n",
    "    axes[1,0].set_xlabel('Objects per Image')\n",
    "    axes[1,0].set_ylabel('Number of Images')\n",
    "    axes[1,0].set_title('Objects per Image Distribution')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Bounding box centers heatmap\n",
    "    heatmap, xedges, yedges = np.histogram2d(annotation_stats['center_x'], annotation_stats['center_y'], bins=20)\n",
    "    extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "    \n",
    "    im = axes[1,1].imshow(heatmap.T, extent=extent, origin='lower', cmap='YlOrRd', alpha=0.8)\n",
    "    axes[1,1].set_xlabel('Center X (normalized)')\n",
    "    axes[1,1].set_ylabel('Center Y (normalized)')\n",
    "    axes[1,1].set_title('Bounding Box Centers Heatmap')\n",
    "    plt.colorbar(im, ax=axes[1,1])\n",
    "    \n",
    "    # 6. Width vs Height scatter plot\n",
    "    axes[1,2].scatter(annotation_stats['bbox_widths'], annotation_stats['bbox_heights'], alpha=0.6, s=20, color='purple')\n",
    "    axes[1,2].set_xlabel('Normalized Width')\n",
    "    axes[1,2].set_ylabel('Normalized Height')\n",
    "    axes[1,2].set_title('Bounding Box Width vs Height')\n",
    "    axes[1,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save plots\n",
    "    plots_dir = Path(\"../results/plots\")\n",
    "    plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(plots_dir / \"annotation_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nAnnotation plots saved to: {plots_dir / 'annotation_analysis.png'}\")\n",
    "\n",
    "# Create annotation plots\nif annotation_stats:\n",
    "    create_annotation_plots(annotation_stats, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Generate Data Quality Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_quality_report(structure_analysis, image_stats, annotation_stats, class_names, dataset_config):\n",
    "    \"\"\"Generate comprehensive data quality report\"\"\"\n",
    "    from datetime import datetime\n",
    "    \n",
    "    report = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"dataset_config\": dataset_config,\n",
    "        \"summary\": {\n",
    "            \"total_images\": 0,\n",
    "            \"total_labels\": 0,\n",
    "            \"total_objects\": 0,\n",
    "            \"class_names\": class_names\n",
    "        },\n",
    "        \"quality_metrics\": {\n",
    "            \"issues_found\": [],\n",
    "            \"recommendations\": [],\n",
    "            \"quality_score\": 0\n",
    "        },\n",
    "        \"splits_analysis\": {},\n",
    "        \"image_statistics\": {},\n",
    "        \"annotation_statistics\": {}\n",
    "    }\n",
    "    \n",
    "    # Basic summary\n",
    "    if structure_analysis:\n",
    "        report[\"summary\"][\"total_images\"] = structure_analysis[\"total_images\"]\n",
    "        report[\"summary\"][\"total_labels\"] = structure_analysis[\"total_labels\"]\n",
    "        \n",
    "        # Splits analysis\n",
    "        for split_name, split_info in structure_analysis[\"splits\"].items():\n",
    "            report[\"splits_analysis\"][split_name] = {\n",
    "                \"images\": split_info[\"images\"],\n",
    "                \"labels\": split_info[\"labels\"],\n",
    "                \"match_rate\": split_info[\"labels\"] / split_info[\"images\"] if split_info[\"images\"] > 0 else 0,\n",
    "                \"missing_labels\": len(split_info[\"missing_labels\"]),\n",
    "                \"missing_images\": len(split_info[\"missing_images\"])\n",
    "            }\n",
    "    \n",
    "    # Image statistics\n",
    "    if image_stats and len(image_stats['widths']) > 0:\n",
    "        report[\"image_statistics\"] = {\n",
    "            \"dimensions\": {\n",
    "                \"width_range\": [min(image_stats['widths']), max(image_stats['widths'])],\n",
    "                \"height_range\": [min(image_stats['heights']), max(image_stats['heights'])],\n",
    "                \"avg_width\": np.mean(image_stats['widths']),\n",
    "                \"avg_height\": np.mean(image_stats['heights'])\n",
    "            },\n",
    "            \"aspect_ratios\": {\n",
    "                \"range\": [min(image_stats['aspect_ratios']), max(image_stats['aspect_ratios'])],\n",
    "                \"average\": np.mean(image_stats['aspect_ratios'])\n",
    "            },\n",
    "            \"file_sizes_kb\": {\n",
    "                \"range\": [min(image_stats['file_sizes']), max(image_stats['file_sizes'])],\n",
    "                \"average\": np.mean(image_stats['file_sizes'])\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # Annotation statistics\n",
    "    if annotation_stats and len(annotation_stats['bbox_widths']) > 0:\n",
    "        total_objects = sum(annotation_stats['class_distribution'].values())\n",
    "        report[\"summary\"][\"total_objects\"] = total_objects\n",
    "        \n",
    "        class_dist = {}\n",
    "        for class_id, count in annotation_stats['class_distribution'].items():\n",
    "            class_name = class_names[class_id] if class_id < len(class_names) else f'class_{class_id}'\n",
    "            class_dist[class_name] = {\n",
    "                \"count\": count,\n",
    "                \"percentage\": count / total_objects * 100\n",
    "            }\n",
    "        \n",
    "        report[\"annotation_statistics\"] = {\n",
    "            \"class_distribution\": class_dist,\n",
    "            \"bbox_stats\": {\n",
    "                \"avg_width\": np.mean(annotation_stats['bbox_widths']),\n",
    "                \"avg_height\": np.mean(annotation_stats['bbox_heights']),\n",
    "                \"avg_area\": np.mean(annotation_stats['bbox_areas'])\n",
    "            },\n",
    "            \"objects_per_image\": {\n",
    "                \"average\": np.mean(annotation_stats['objects_per_image']),\n",
    "                \"range\": [min(annotation_stats['objects_per_image']), max(annotation_stats['objects_per_image'])]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # Quality assessment\n",
    "    quality_score = 100\n",
    "    issues = []\n",
    "    recommendations = []\n",
    "    \n",
    "    # Check for structural issues\n",
    "    if structure_analysis and structure_analysis['issues']:\n",
    "        issues.extend(structure_analysis['issues'])\n",
    "        quality_score -= len(structure_analysis['issues']) * 10\n",
    "    \n",
    "    # Check dataset size\n",
    "    if report[\"summary\"][\"total_images\"] < 1000:\n",
    "        issues.append(f\"Dataset size is small ({report['summary']['total_images']} images). Consider adding more data.\")\n",
    "        quality_score -= 15\n",
    "    \n",
    "    # Check class balance\n",
    "    if \"class_distribution\" in report[\"annotation_statistics\"]:\n",
    "        class_percentages = [info[\"percentage\"] for info in report[\"annotation_statistics\"][\"class_distribution\"].values()]\n",
    "        if max(class_percentages) > 90:\n",
    "            issues.append(\"Severe class imbalance detected. Consider balancing the dataset.\")\n",
    "            quality_score -= 20\n",
    "        elif max(class_percentages) > 80:\n",
    "            issues.append(\"Moderate class imbalance detected.\")\n",
    "            quality_score -= 10\n",
    "    \n",
    "    # Check image dimensions consistency\n",
    "    if image_stats and len(image_stats['widths']) > 0:\n",
    "        width_std = np.std(image_stats['widths'])\n",
    "        height_std = np.std(image_stats['heights'])\n",
    "        \n",
    "        if width_std > 500 or height_std > 500:\n",
    "            issues.append(\"High variation in image dimensions. Consider resizing for consistent training.\")\n",
    "            quality_score -= 5\n",
    "    \n",
    "    # Recommendations\n",
    "    if report[\"summary\"][\"total_images\"] < 1500:\n",
    "        recommendations.append(\"Consider augmenting the dataset to reach 1500+ images for better training results.\")\n",
    "    \n",
    "    if image_stats and np.mean(image_stats['widths']) < 640:\n",
    "        recommendations.append(\"Average image size is below 640px. Consider using higher resolution images.\")\n",
    "    \n",
    "    recommendations.extend([\n",
    "        \"Verify that license plate annotations are accurate and complete.\",\n",
    "        \"Check for diverse lighting conditions and viewing angles.\",\n",
    "        \"Ensure Indonesian license plate formats are well represented.\"\n",
    "    ])\n",
    "    \n",
    "    report[\"quality_metrics\"] = {\n",
    "        \"issues_found\": issues,\n",
    "        \"recommendations\": recommendations,\n",
    "        \"quality_score\": max(0, quality_score)  # Ensure non-negative\n",
    "    }\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Generate report\ndata_quality_report = generate_data_quality_report(\n",
    "    structure_analysis, image_stats, annotation_stats, class_names, dataset_config\n",
    ")\n",
    "\n",
    "# Display report summary\nprint(\"\\nüìã Data Quality Report Summary\")\nprint(\"=\" * 50)\nprint(f\"Generated: {data_quality_report['timestamp']}\")\nprint(f\"Total Images: {data_quality_report['summary']['total_images']}\")\nprint(f\"Total Objects: {data_quality_report['summary']['total_objects']}\")\nprint(f\"Quality Score: {data_quality_report['quality_metrics']['quality_score']}/100\")\n\nif data_quality_report['quality_metrics']['issues_found']:\n    print(f\"\\n‚ö†Ô∏è  Issues Found ({len(data_quality_report['quality_metrics']['issues_found'])}):\")\n    for issue in data_quality_report['quality_metrics']['issues_found']:\n        print(f\"  - {issue}\")\n\nprint(f\"\\nüí° Recommendations ({len(data_quality_report['quality_metrics']['recommendations'])}):\")\nfor rec in data_quality_report['quality_metrics']['recommendations'][:3]:  # Show first 3\n    print(f\"  - {rec}\")\n\n# Save report\nreports_dir = Path(\"../results/reports\")\nreports_dir.mkdir(parents=True, exist_ok=True)\n\nwith open(reports_dir / \"data_quality_report.json\", 'w') as f:\n    json.dump(data_quality_report, f, indent=2, default=str)\n\nprint(f\"\\nüìÑ Full report saved to: {reports_dir / 'data_quality_report.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Indonesian License Plate Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indonesian License Plate Pattern Reference\nprint(\"üöó Indonesian License Plate Patterns Reference\")\nprint(\"=\" * 50)\n\nindonesian_patterns = {\n    \"Standard Format\": \"[Area Code] [Number] [Suffix]\",\n    \"Examples\": [\n        \"B 1234 ABC (Jakarta)\",\n        \"D 5678 XY (Bandung)\", \n        \"L 9012 DEF (Surabaya)\",\n        \"AA 1234 BB (Kedu/Magelang)\"\n    ],\n    \"Area Codes\": {\n        \"B\": \"Jakarta\",\n        \"D\": \"Bandung\", \n        \"F\": \"Bogor\",\n        \"L\": \"Surabaya\",\n        \"N\": \"Malang\",\n        \"AA\": \"Kedu (Magelang)\",\n        \"AB\": \"Yogyakarta\",\n        \"AD\": \"Solo\"\n    },\n    \"Color Codes\": {\n        \"Black on White\": \"Private vehicles\",\n        \"White on Black\": \"Government/Military\", \n        \"White on Red\": \"Diplomatic vehicles\",\n        \"Yellow on Black\": \"Public transport\"\n    }\n}\n\nfor category, info in indonesian_patterns.items():\n    print(f\"\\n{category}:\")\n    if isinstance(info, dict):\n        for key, value in info.items():\n            print(f\"  {key}: {value}\")\n    elif isinstance(info, list):\n        for item in info:\n            print(f\"  - {item}\")\n    else:\n        print(f\"  {info}\")\n\nprint(\"\\nüìù Notes for Training:\")\nprint(\"  - Focus on detecting plate regions (bounding boxes)\")\nprint(\"  - OCR (text recognition) will be handled separately with PaddleOCR\")\nprint(\"  - Model should work with various plate colors and sizes\")\nprint(\"  - Consider motorcycle plates (smaller, different aspect ratio)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook provides comprehensive analysis of the Indonesian license plate dataset including:\n",
    "\n",
    "### ‚úÖ Completed Analysis:\n",
    "- Dataset structure verification\n",
    "- Image statistics (dimensions, aspect ratios, file sizes)\n",
    "- Annotation quality assessment\n",
    "- Class distribution analysis\n",
    "- Data quality report generation\n",
    "- Indonesian license plate pattern reference\n",
    "\n",
    "### üìä Key Outputs:\n",
    "- Sample images with annotations visualized\n",
    "- Statistical plots saved to `results/plots/`\n",
    "- Quality report saved to `results/reports/`\n",
    "- Issues and recommendations identified\n",
    "\n",
    "### üéØ Next Steps:\n",
    "1. **Review the data quality report** and address any critical issues\n",
    "2. **Proceed to Notebook 03** for data preparation and preprocessing\n",
    "3. **Clean and augment data** based on findings from this analysis\n",
    "4. **Prepare YOLO configuration** files for training\n",
    "\n",
    "### üîÑ If Issues Found:\n",
    "- **Missing labels**: Remove images without corresponding labels\n",
    "- **Class imbalance**: Consider data augmentation or resampling\n",
    "- **Inconsistent dimensions**: Implement consistent resizing strategy\n",
    "- **Quality issues**: Manual review and cleanup of problematic samples\n",
    "\n",
    "The dataset is now thoroughly analyzed and ready for preprocessing in the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}